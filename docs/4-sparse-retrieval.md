# 教師あり疎検索

大規模言語モデルによる検索モデルは密ベクトルによる検索だけではなく，
疎ベクトルによる検索にも応用することができます．
以下では，教師あり疎ベクトルの代表的な手法であるSPLADEを，PyTerrierと組み合わせて動作させてみます．

## 単語一致による検索モデルの解釈

従来の単語一致による検索モデルは，クエリと文書を疎ベクトルによって表現し，
それらの類似度を計算することによって文書を順位付けていると解釈することもできます．
例えば，クエリ「つくば　観光」は，以下のような語彙数次元のベクトルqによって表現することができます：
```
q = (0, 0, ..., 0, 1, 0, ..., 0, 1, 0, ..., 0)
```
各語彙には自然数が割り当てられているものとし，
たとえば，「つくば」と「観光」にはそれぞれ1245と2456が割り当てられているとすれば，
上記のベクトルで「1」になっている次元は，それぞれ，1245番目と2456番目の次元です．

同様に，「つくばでつくば観光」という4語から構成される文書は，以下のようなベクトルdによって表現されます．
```
d = (0, 1, ..., 0, 1, 0, ..., 0, 1, 0, ..., 0)
```
ただし，「で」という単語には2が割り当てられているとします．
そのため，qとは2次元目だけが違うベクトルで表現されることになります．

文書のベクトルは単語の出現回数や珍しさ，文書の長さなどによって，単語の重み（重要度）を変えることがあります．たとえば，以下のように，重み1の代わりに「単語の出現回数」に置き換えることがあります：
```
d = (0, 1, ..., 0, 2, 0, ..., 0, 1, 0, ..., 0)
```
「つくば」という単語は2回，それ以外の単語は1回文書中に出現しているので，1245次元目だけが2，それ以外は1のままです．

このような重み付けの方法は複数提案されており，`scripts/terrier_retrieve.py`の`wmodel`引数にはこの重み付け方法を指定することができます．`BM25`や`TF_IDF`などは，このように，文書を疎ベクトルで表現するときの重み付けモデル（方法）を表していたということです．

疎ベクトルで表現されたらあとは密ベクトルの検索と同様に，ベクトル同士の類似度を計算して，文書を順位付けます．ただし，密ベクトルとは違い，疎ベクトルの場合には従来の転置索引によって高速な検索が可能です．

## SPLADEによるクエリと文書のエンコーディング

SPLADEは，BERTなどの大規模言語モデルによって，クエリと文書を疎ベクトルによって表現し，文書を順位付ける検索モデルです．例えば，SPLADEを用いると「筑波大学では何の研究が行われているか？」というクエリは以下のような疎ベクトルで表現されます：
```
筑波 2.00
つくば 1.65
研究 1.62
大学 1.37
実験 0.55
学生 0.42
分析 0.37
国立 0.36
キャンパス 0.36
```
（参考: https://huggingface.co/aken12/splade-japanese-efficient）
これらの語に対する重みは，各語に対応付けられた次元（自然数）の値として用いられ，疎ベクトルを構成します．
単語一致による検索モデルとは異なり，クエリ中の語以外の語にも重みが付けられていること，
また，クエリ中で1回しか登場していない語同士であっても異なる重みが付けられていることに注目してください．
クエリのみでなく，文書も同様に，文書中の語以外の語に適切な重み付けが行われます．
これらは大規模言語モデルを用いることで実現されており，クエリと文書で共通する語がなくてもその文書を上位に順位付けできる可能性があることが，
従来の単語一致による検索モデルにはない利点です．

### 文書エンコーディングと転置索引の作成

SPLADEによる文書のエンコーディングおよび転置索引の作成は以下のコマンドで実行できます：
```bash
$ poetry run python scripts/splade_inverted_index.py \
    mpkato/miracl-japanese-small-corpus \
    ./splade_index \
    aken12/splade-japanese-v3 \
    --split train \
    --mult 10
```

`scripts/terrier_inverted_index.py`との違いは以下の3点です：
- 索引のファイルパスを変えていること
- `model_name_or_path`引数（3番目の引数）が追加されていること
- `--mult`キーワード引数を指定していること

`model_name_or_path`にはSPLADEモデルを指定する必要があり，
この例では日本語検索用に学習されたSPLADEモデル [aken12/splade-japanese-v3](https://huggingface.co/aken12/splade-japanese-v3) を利用しています．
`--mult`の値は各語の重みにかけ合わされ，重みの小数点以下を切り捨てし，重みが0でない単語のみを利用するために用いられます．なお，推奨値は100ですが索引付けに時間がかかりすぎるためこの例では10を指定しています．

### クエリのエンコーディングと転置索引による検索

SPLADEによる検索は以下のコマンドで実行できます：
```bash
$ poetry run python scripts/splade_retrieve.py \
    mpkato/miracl-japanese-small \
    ./splade_index \
    aken12/splade-japanese-v3 \
    ./results/splade.trec \
    --split dev
```

`scripts/terrier_retrieve.py`との違いは，`model_name_or_path`にSPLADEモデルを，
`index_filepath`にSPLADEの転置索引を，`output_filepath`にBM25などとは異なるファイルパスを指定している点です．

SPLADEは単語一致による検索モデルと比べ時間がかかります．これは，SPLADEではクエリのエンコーディングが必要であり，
また，転置索引において各文書が含む単語が肥大化しているためです．


## 評価

これまでと同様に評価を行います．追加学習をしていないDPRと同等程度の性能が得られます．

```bash
$ poetry run ir_measures qrels.miracl-v1.0-ja-dev.tsv results/splade.trec nDCG@10 RR
```

```bash
nDCG@10 0.6581
RR      0.6794
```
